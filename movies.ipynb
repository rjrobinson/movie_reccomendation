{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# import pandas as pd\n",
    "# \n",
    "# def load_data_with_progress(filename, chunk_size=100000):\n",
    "#     \"\"\"Loads a CSV file in chunks with a progress bar.\"\"\"\n",
    "#     chunks = []\n",
    "#     with tqdm(total=100, desc=f\"Reading {filename}\") as pbar:\n",
    "#         for chunk in pd.read_csv(filename, sep='\\t', compression='gzip', chunksize=chunk_size, low_memory=False):\n",
    "#             chunks.append(chunk)\n",
    "#             pbar.update(1)\n",
    "#     return pd.concat(chunks, ignore_index=True)\n",
    "# \n",
    "# def merge_data_with_progress(dataframes, on_column):\n",
    "#     \"\"\"Merges multiple DataFrames with a progress bar.\"\"\"\n",
    "#     with tqdm(total=len(dataframes) - 1, desc=\"Merging DataFrames\") as pbar:\n",
    "#         merged_data = dataframes[0]\n",
    "#         for df in dataframes[1:]:\n",
    "#             merged_data = pd.merge(merged_data, df, on=on_column)\n",
    "#             pbar.update(1)\n",
    "#     return merged_data\n",
    "# \n",
    "# # Load the IMDB data files\n",
    "# title_basics = load_data_with_progress('imdb/title.basics.tsv.gz')\n",
    "# title_crew = load_data_with_progress('imdb/title.crew.tsv.gz')\n",
    "# name_basics = load_data_with_progress('imdb/name.basics.tsv.gz') # If needed\n",
    "# title_ratings = pd.read_csv('imdb/title.ratings.tsv.gz', sep='\\t', compression='gzip', low_memory=False)\n",
    "# \n",
    "# title_akas = load_data_with_progress('imdb/title.akas.tsv.gz')\n",
    "# title_akas.rename(columns={'titleId': 'tconst'}, inplace=True)\n",
    "# \n",
    "# us_movies = title_akas[title_akas['region'] == 'US']\n",
    "# # Merge the loaded data into a single DataFrame\n",
    "# dataframes_to_merge = [title_basics, title_ratings, title_crew, name_basics, us_movies]\n",
    "# merged_data = merge_data_with_progress(dataframes_to_merge, 'tconst')\n",
    "# \n",
    "# dataframes_to_merge_titles = [title_basics, title_ratings, title_crew]\n",
    "# merged_titles = merge_data_with_progress(dataframes_to_merge_titles, 'tconst')\n",
    "# directors = merged_titles['directors'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('nconst')\n",
    "# writers = merged_titles['writers'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('nconst')\n",
    "# director_names = directors.reset_index().merge(name_basics, on='nconst')\n",
    "# writer_names = writers.reset_index().merge(name_basics, on='nconst')\n",
    "# merged_data = pd.merge(merged_titles, us_movies, on='tconst', how='inner')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_with_progress(filename, chunk_size=100000):\n",
    "    chunks = []\n",
    "    with tqdm(total=100, desc=f\"Reading {filename}\") as pbar:\n",
    "        for chunk in pd.read_csv(filename, sep='\\t', compression='gzip', chunksize=chunk_size, low_memory=False):\n",
    "            chunks.append(chunk)\n",
    "            pbar.update(1)\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "def merge_data_with_progress(dataframes, on_column):\n",
    "    with tqdm(total=len(dataframes) - 1, desc=\"Merging DataFrames\") as pbar:\n",
    "        merged_data = dataframes[0]\n",
    "        for df in dataframes[1:]:\n",
    "            merged_data = pd.merge(merged_data, df, on=on_column)\n",
    "            pbar.update(1)\n",
    "    return merged_data\n",
    "\n",
    "# Load the IMDB data files\n",
    "title_basics = load_data_with_progress('imdb/title.basics.tsv.gz')\n",
    "title_crew = load_data_with_progress('imdb/title.crew.tsv.gz')\n",
    "name_basics = load_data_with_progress('imdb/name.basics.tsv.gz')\n",
    "title_ratings = pd.read_csv('imdb/title.ratings.tsv.gz', sep='\\t', compression='gzip', low_memory=False)\n",
    "\n",
    "# Merge the title-related DataFrames\n",
    "dataframes_to_merge_titles = [title_basics, title_ratings, title_crew]\n",
    "merged_titles = merge_data_with_progress(dataframes_to_merge_titles, 'tconst')\n",
    "# Replace '\\N' with NaN\n",
    "merged_data.replace('\\\\N', pd.NA, inplace=True)\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "merged_data['startYear'] = pd.to_numeric(merged_data['startYear'], errors='coerce')\n",
    "merged_data['endYear'] = pd.to_numeric(merged_data['endYear'], errors='coerce')\n",
    "merged_data['runtimeMinutes'] = pd.to_numeric(merged_data['runtimeMinutes'], errors='coerce')\n",
    "\n",
    "# Optionally, filter adult content\n",
    "merged_data = merged_data[merged_data['isAdult'] == '0']\n",
    "# Drop the row with missing startYear\n",
    "merged_data.dropna(subset=['startYear'], inplace=True)\n",
    "# Fill endYear with a placeholder\n",
    "merged_data['endYear'].fillna('Unknown', inplace=True)\n",
    "# Fill missing runtimeMinutes with the median value\n",
    "merged_data['runtimeMinutes'].fillna(merged_data['runtimeMinutes'].median(), inplace=True)\n",
    "# Fill missing genres with \"Unknown\"\n",
    "merged_data['genres'].fillna('Unknown', inplace=True)\n",
    "# Fill missing directors and writers with \"Unknown\"\n",
    "merged_data['directors'].fillna('Unknown', inplace=True)\n",
    "merged_data['writers'].fillna('Unknown', inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select the numerical features\n",
    "numerical_features = merged_data[['averageRating', 'numVotes']]  # Add more features as needed\n",
    "\n",
    "# If you have categorical features like genres, encode them using one-hot encoding\n",
    "encoded_genres = pd.get_dummies(merged_data['genres'])\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([numerical_features, encoded_genres], axis=1)\n",
    "\n",
    "# Scale the features if necessary\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Now, you can use X_scaled in your K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Convert 'runtimeMinutes' to numeric, handling any non-numeric values\n",
    "merged_data['runtimeMinutes'] = pd.to_numeric(merged_data['runtimeMinutes'], errors='coerce')\n",
    "\n",
    "# Select the numerical features\n",
    "numerical_features = merged_data[['averageRating', 'numVotes', 'runtimeMinutes']].fillna(0)\n",
    "\n",
    "# Split 'genres' into individual genres and then one-hot encode\n",
    "genres_split = merged_data['genres'].str.get_dummies(sep=',')\n",
    "encoded_genres = pd.get_dummies(genres_split)\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([numerical_features, encoded_genres], axis=1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Assign cluster labels\n",
    "merged_data['cluster'] = kmeans.labels_\n",
    "\n",
    "# Analyze clusters - print the mean of each feature per cluster\n",
    "for i in range(5):\n",
    "    print(merged_data[merged_data['cluster'] == i][['averageRating', 'numVotes', 'runtimeMinutes']].mean())\n",
    "\n",
    "# Example recommendation function\n",
    "def recommend_movie(movie_title, top_n=5):\n",
    "    filtered_movies = merged_data[merged_data['primaryTitle'] == movie_title]\n",
    "\n",
    "    if filtered_movies.empty:\n",
    "        print(f\"No movie found with title {movie_title}\")\n",
    "        return []\n",
    "\n",
    "    cluster = filtered_movies['cluster'].iloc[0]\n",
    "    recommendations = merged_data[merged_data['cluster'] == cluster]\n",
    "\n",
    "    # Sort recommendations by rating and number of votes\n",
    "    recommendations = recommendations.sort_values(by=['averageRating', 'numVotes'], ascending=False)\n",
    "\n",
    "    # Select top N recommendations\n",
    "    top_recommendations = recommendations.head(top_n)\n",
    "\n",
    "    # Prepare information for display\n",
    "    recommended_movies = []\n",
    "    for index, row in top_recommendations.iterrows():\n",
    "        movie_info = {\n",
    "            'title': row['primaryTitle'],\n",
    "            'genre': row['genres'],\n",
    "            'rating': row['averageRating'],\n",
    "            'votes': row['numVotes'],\n",
    "            # Add more details as needed\n",
    "        }\n",
    "        recommended_movies.append(movie_info)\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "# Recommendation function based on cast member\n",
    "def recommend_by_director(director_name, top_n=5):\n",
    "    filtered_movies = merged_data[merged_data['directors'] != 'Unknown']\n",
    "    filtered_movies = filtered_movies[filtered_movies['directors'].str.contains(director_name, case=False)]\n",
    "\n",
    "    if filtered_movies.empty:\n",
    "        print(f\"No movies found directed by {director_name}\")\n",
    "        return []\n",
    "\n",
    "    recommendations = filtered_movies.sort_values(by=['averageRating', 'numVotes'], ascending=False)\n",
    "\n",
    "    # Select top N recommendations\n",
    "    top_recommendations = recommendations.head(top_n)\n",
    "\n",
    "    # Prepare information for display\n",
    "    recommended_movies = []\n",
    "    for index, row in top_recommendations.iterrows():\n",
    "        movie_info = {\n",
    "            'title': row['primaryTitle'],\n",
    "            'genre': row['genres'],\n",
    "            'rating': row['averageRating'],\n",
    "            'votes': row['numVotes'],\n",
    "            # Add more details as needed\n",
    "        }\n",
    "        recommended_movies.append(movie_info)\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "\n",
    "# Recommendation function based on genre\n",
    "def recommend_by_genre(genre, top_n=5):\n",
    "    filtered_movies = merged_data[merged_data['genres'].str.contains(genre, case=False, na=False)]\n",
    "\n",
    "    if filtered_movies.empty:\n",
    "        print(f\"No movies found in genre {genre}\")\n",
    "        return []\n",
    "\n",
    "    recommendations = filtered_movies.sort_values(by=['averageRating', 'numVotes'], ascending=False)\n",
    "\n",
    "    # Select top N recommendations\n",
    "    top_recommendations = recommendations.head(top_n)\n",
    "\n",
    "    # Prepare information for display\n",
    "    recommended_movies = []\n",
    "    for index, row in top_recommendations.iterrows():\n",
    "        movie_info = {\n",
    "            'title': row['primaryTitle'],\n",
    "            'genre': row['genres'],\n",
    "            'rating': row['averageRating'],\n",
    "            'votes': row['numVotes'],\n",
    "            # Add more details as needed\n",
    "        }\n",
    "        recommended_movies.append(movie_info)\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "208572f545c05f19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c54bf20b416ae0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre Processing and Merging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e23eece334d7977"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "merged_data['averageRating'].hist(bins=20)\n",
    "plt.title('Distribution of Average Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b56faa5d310082ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(merged_data['averageRating'], merged_data['numVotes'])\n",
    "plt.title('Scatter plot of Average Ratings vs Number of Votes')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Number of Votes')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5b870accbfeecb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_data = merged_data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3374d7ad64a66c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data['genres'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Genres')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16e6aa1dfed22a4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select the numerical features\n",
    "numerical_features = merged_data[['averageRating', 'numVotes']]  # Add more features as needed\n",
    "\n",
    "# If you have categorical features like genres, encode them using one-hot encoding\n",
    "encoded_genres = pd.get_dummies(merged_data['genres'])\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([numerical_features, encoded_genres], axis=1)\n",
    "\n",
    "# Scale the features if necessary\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Now, you can use X_scaled in your K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_scaled)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dedf2c85f9c2bdd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Convert 'runtimeMinutes' to numeric, handling any non-numeric values\n",
    "merged_data['runtimeMinutes'] = pd.to_numeric(merged_data['runtimeMinutes'], errors='coerce')\n",
    "\n",
    "# Select the numerical features\n",
    "numerical_features = merged_data[['averageRating', 'numVotes', 'runtimeMinutes']].fillna(0)\n",
    "\n",
    "# Split 'genres' into individual genres and then one-hot encode\n",
    "genres_split = merged_data['genres'].str.get_dummies(sep=',')\n",
    "encoded_genres = pd.get_dummies(genres_split)\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([numerical_features, encoded_genres], axis=1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_scaled)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54bd71b5c40419be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6a0c1dc393190c1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# recommend_movie(\"Blue Shadow Virus\")\n",
    "recommend_by_genre(\"Action\")\n",
    "# recommend_by_director(\"nm12197316\")\n",
    "# Print out the top 5 actors\n",
    "# top_directors = merged_data['directors'].str.split(', ', expand=True).stack().value_counts().head(50)\n",
    "# print(top_directors)\n",
    "# merged_data.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eafd8ea394b14e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_movie_titles = merged_data['primaryTitle'].unique().tolist()\n",
    "\n",
    "# Print the list of all movie titles\n",
    "for title in all_movie_titles:\n",
    "    print(title)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6ac500f57a12e39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbca26cc5279025b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "caf79457d313898e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
